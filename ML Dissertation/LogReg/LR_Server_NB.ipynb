{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import LR_Utils as utils\n",
    "from flwr.common import NDArrays, Scalar\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import metrics \n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Tuple, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_round(server_round: int) -> Dict:\n",
    "    \"\"\"Send round number to client.\"\"\"\n",
    "    return {\"server_round\": server_round}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluate_fn(model: LogisticRegression):\n",
    "    \"\"\"Return an evaluation function for server-side evaluation.\"\"\"\n",
    "\n",
    "    _, (X_test, y_test) = utils.load_Data()\n",
    "\n",
    "    def evaluate(\n",
    "        server_round: int, parameters: NDArrays, config: Dict[str, Scalar]\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        utils.set_model_params(model, parameters)\n",
    "        loss = log_loss(y_test, model.predict_proba(X_test))\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        return ({\"Sever Loss\":loss}, {\"Server Accuracy\": accuracy})\n",
    "        \n",
    "    return evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = LogisticRegression()\n",
    "    utils.set_initial_params(model)\n",
    "    strategy = fl.server.strategy.FedAvg(\n",
    "        min_available_clients=2,\n",
    "        evaluate_fn=get_evaluate_fn(model),\n",
    "        on_fit_config_fn=fit_round,\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl.server.start_server(\n",
    "    server_address=\"127.0.0.1:8080\",\n",
    "    strategy=strategy,\n",
    "    config=fl.server.ServerConfig(num_rounds=300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv(r\"C:\\Users\\adamc\\Work\\HomeLab\\ML Dissertation\\Datasets\\UNSW-NB15\\UNSW_NB15_training-set.csv\")\n",
    "testDF = pd.read_csv(r\"C:\\Users\\adamc\\Work\\HomeLab\\ML Dissertation\\Datasets\\UNSW-NB15\\UNSW_NB15_testing-set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.shape\n",
    "\n",
    "testDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = trainDF.dropna()\n",
    "trainDF = trainDF.drop_duplicates()\n",
    "\n",
    "testDF = testDF.dropna()\n",
    "testDF = testDF.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Redundant Columns\n",
    "trainDF = trainDF.drop(columns='id')\n",
    "trainDF = trainDF.drop(columns='label')\n",
    "\n",
    "testDF = testDF.drop(columns='id')\n",
    "testDF = testDF.drop(columns='label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import one hot encoder from sklearn\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "enc.fit(trainDF[['proto','service','state','attack_cat']])  # Fit encoder on training data\n",
    "\n",
    "train_encoded = enc.transform(trainDF[['proto','service','state','attack_cat']])\n",
    "test_encoded = enc.transform(testDF[['proto','service','state','attack_cat']])\n",
    "\n",
    "# Replace 'proto','service','state','attack_cat' column with encoded data\n",
    "trainDF = pd.concat([trainDF.drop(['proto','service','state','attack_cat'], axis=1), pd.DataFrame(train_encoded, columns=enc.get_feature_names_out(['proto','service','state','attack_cat']))], axis=1)\n",
    "testDF = pd.concat([testDF.drop(['proto','service','state','attack_cat'], axis=1), pd.DataFrame(test_encoded, columns=enc.get_feature_names_out(['proto','service','state','attack_cat']))], axis=1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create classes variable listing all outcomes of dataset\n",
    "class_name = ['attack_cat_Analysis',\n",
    " 'attack_cat_Backdoor',\n",
    " 'attack_cat_DoS',\n",
    " 'attack_cat_Exploits',\n",
    " 'attack_cat_Fuzzers',\n",
    " 'attack_cat_Generic',\n",
    " 'attack_cat_Normal',\n",
    " 'attack_cat_Reconnaissance',\n",
    " 'attack_cat_Shellcode',\n",
    " 'attack_cat_Worms']\n",
    "# Select everything other than classes\n",
    "x_train = trainDF.drop(columns=class_name)\n",
    "x_test = testDF.drop(columns=class_name)\n",
    "# Select only classes\n",
    "y_test = testDF[class_name]\n",
    "y_train = trainDF[class_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_test = np.argmax(y_test,axis=1)\n",
    "y_train = np.argmax(y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Unique values:\", unique)\n",
    "print(\"Counts:\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [col for col in trainDF.columns if col.startswith('attack_cat')]\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports minmaxscaler to normalise (Scale) data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(trainDF)\n",
    "\n",
    "trainDF = scaler.transform(trainDF)\n",
    "testDF = scaler.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
