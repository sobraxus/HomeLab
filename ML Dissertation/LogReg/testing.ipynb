{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flwr as fl\n",
    "import LR_Utils as utils\n",
    "from flwr.common import NDArrays, Scalar\n",
    "from sklearn.metrics import log_loss, ConfusionMatrixDisplay\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Tuple, Dict, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv(r\"C:\\Users\\adamc\\Work\\HomeLab\\ML Dissertation\\Datasets\\UNSW-NB15\\UNSW_NB15_training-set.csv\")\n",
    "testDF = pd.read_csv(r\"C:\\Users\\adamc\\Work\\HomeLab\\ML Dissertation\\Datasets\\UNSW-NB15\\UNSW_NB15_testing-set.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.get_dummies(trainDF, columns=['proto', 'service', 'state', 'attack_cat'])\n",
    "testDF = pd.get_dummies(testDF, columns=['proto', 'service', 'state', 'attack_cat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175341, 205)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF = trainDF.drop('label', axis=1)\n",
    "trainDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF = testDF['label']\n",
    "testDF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82332, 45)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    X_train, X_test, y_train, y_test = train_test_split(trainDF, testDF, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = trainDF.dropna()\n",
    "trainDF = trainDF.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Redundant Columns\n",
    "trainDF = trainDF.drop(columns='id')\n",
    "trainDF = trainDF.drop(columns='label')\n",
    "\n",
    "testDF = testDF.drop(columns='id')\n",
    "testDF = testDF.drop(columns='label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import one hot encoder from sklearn\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "enc.fit(trainDF[['proto','service','state','attack_cat']])  # Fit encoder on training data\n",
    "\n",
    "train_encoded = enc.transform(trainDF[['proto','service','state','attack_cat']])\n",
    "test_encoded = enc.transform(testDF[['proto','service','state','attack_cat']])\n",
    "# Replace 'proto','service','state','attack_cat' column with encoded data\n",
    "trainDF = pd.concat([trainDF.drop(['proto','service','state','attack_cat'], axis=1), pd.DataFrame(train_encoded, columns=enc.get_feature_names_out(['proto','service','state','attack_cat']))], axis=1)\n",
    "testDF = pd.concat([testDF.drop(['proto','service','state','attack_cat'], axis=1), pd.DataFrame(test_encoded, columns=enc.get_feature_names_out(['proto','service','state','attack_cat']))], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create classes variable listing all outcomes of dataset\n",
    "class_name = ['attack_cat_Analysis',\n",
    " 'attack_cat_Backdoor',\n",
    " 'attack_cat_DoS',\n",
    " 'attack_cat_Exploits',\n",
    " 'attack_cat_Fuzzers',\n",
    " 'attack_cat_Generic',\n",
    " 'attack_cat_Normal',\n",
    " 'attack_cat_Reconnaissance',\n",
    " 'attack_cat_Shellcode',\n",
    " 'attack_cat_Worms']\n",
    "# Select everything other than classes\n",
    "x_train = trainDF.drop(columns=class_name)\n",
    "x_test = testDF.drop(columns=class_name)\n",
    "# Select only classes\n",
    "y_test = testDF[class_name]\n",
    "y_train = trainDF[class_name]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "y_train = pd.DataFrame(scaler.fit_transform(y_train),columns=y_train.columns)\n",
    "y_test = pd.DataFrame(scaler.transform(y_test), columns=y_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = x_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.iloc[600:610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rainDF.nunique()\n",
    "\n",
    "#get unique values of is_sm_ips_ports and show them\n",
    "\n",
    "trainDF['tcp'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF[609:610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = enc.get_feature_names_out(['proto','service','state','attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_test = np.argmax(y_test,axis=1)\n",
    "y_train = np.argmax(y_train,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[609:610]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_test, return_counts=True)\n",
    "print(\"Unique values:\", unique)\n",
    "print(\"Counts:\", counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF = pd.read_csv(r\"C:\\Users\\adamc\\Work\\HomeLab\\ML Dissertation\\Datasets\\UNSW-NB15\\UNSW_NB15_training-set.csv\")\n",
    "testDF = pd.read_csv(r\"C:\\Users\\adamc\\Work\\HomeLab\\ML Dissertation\\Datasets\\UNSW-NB15\\UNSW_NB15_testing-set.csv\")\n",
    "\n",
    "    #Dropping null and duplicate values\n",
    "\n",
    "    #Create an if statement for if there are any null values or duplicates in trainDF and drop them if true\n",
    "if(trainDF.isnull().values.sum() != 0):\n",
    "    trainDF = trainDF.dropna()\n",
    "    \n",
    "if(trainDF.nunique().values.sum() != 0):\n",
    "       trainDF = trainDF.drop_duplicates()\n",
    "\n",
    "    #Dropping redundant columns\n",
    "trainDF.drop(labels=\"id\", axis=1, inplace=True)\n",
    "trainDF.drop(labels=\"label\", axis=1, inplace=True)\n",
    "\n",
    "testDF.drop(labels=\"id\", axis=1, inplace=True)\n",
    "testDF.drop(labels=\"label\", axis=1, inplace=True)\n",
    "    \n",
    "    #Apply one-hot encoding to 'proto','service','state','attack_cat' columns\n",
    "enc = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "enc.fit(trainDF[['proto','service','state','attack_cat']])  # Fit encoder on training data\n",
    "\n",
    "train_encoded = enc.transform(trainDF[['proto','service','state','attack_cat']])\n",
    "test_encoded  = enc.transform(testDF[['proto','service','state','attack_cat']])\n",
    "\n",
    "    # Replace 'proto','service','state','attack_cat' column with encoded data\n",
    "trainDF = pd.concat([trainDF.drop(['proto','service','state','attack_cat'], axis=1), pd.DataFrame(train_encoded, columns=enc.get_feature_names_out(['proto','service','state','attack_cat']))], axis=1)\n",
    "testDF  = pd.concat([testDF.drop(['proto','service','state','attack_cat'],  axis=1), pd.DataFrame(test_encoded,  columns=enc.get_feature_names_out(['proto','service','state','attack_cat']))], axis=1)\n",
    "    \n",
    "\n",
    "    #Create classes variable listing all outcomes of dataset\n",
    "class_name = ['attack_cat_Analysis',\n",
    "    'attack_cat_Backdoor',\n",
    "    'attack_cat_DoS',\n",
    "    'attack_cat_Exploits',\n",
    "    'attack_cat_Fuzzers',\n",
    "    'attack_cat_Generic',\n",
    "    'attack_cat_Normal',\n",
    "    'attack_cat_Reconnaissance',\n",
    "    'attack_cat_Shellcode',\n",
    "    'attack_cat_Worms']\n",
    "\n",
    "    # Select everything other than classes\n",
    "x_train = trainDF.drop(columns=class_name)\n",
    "x_test = testDF.drop(columns=class_name)\n",
    "    # Select only classes\n",
    "y_test = testDF[class_name]\n",
    "y_train = trainDF[class_name]\n",
    "\n",
    "\n",
    "x_train, y_train = x_train[:60000], y_train[:60000]\n",
    "x_test, y_test = x_test[60000:], y_test[60000:]\n",
    "print ((x_train,y_train), (x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_columns = [col for col in trainDF.columns if col.startswith('attack_cat')]\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports minmaxscaler to normalise (Scale) data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(trainDF)\n",
    "\n",
    "trainDF = scaler.transform(trainDF)\n",
    "testDF = scaler.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import flwr as fl\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn as skl\n",
    "from sklearn import metrics, linear_model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.ensemble import IsolationForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing##\n",
    "columns = ([])\n",
    "example1 = pd.read_csv('HomeLab\\ML Dissertation\\Datasets\\CIC-2017') #Network Actiity\n",
    "example2 = pd.read_csv('HomeLab\\ML Dissertation\\Datasets\\ember2018') #Host acitivty\n",
    "merged_df = pd.concat([example1, example2], names= columns) #Merged Network and Host Activity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train.csv\", names=, )\n",
    "\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "validation_df = pd.read_csv(\"validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
